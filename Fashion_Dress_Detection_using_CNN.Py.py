# -*- coding: utf-8 -*-
"""Fashion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kH0Jnb-Mrlt30QjwJlCnLbWZhPLNPo7T
"""

"""**Project Fasion Classification on Convolutional Neural Network on 60000 Fasion Images (Data in NP Array)**

Test Convolutional Neural Network on 10000 Fashion Images(Data in NP Array)
"""



"""*Lets Import Libraries*"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from tensorflow import keras

"""*Load Dataset*"""

(X_train, Y_train), (X_test, Y_test) = keras.datasets.fashion_mnist.load_data()

X_test.shape, Y_test.shape

X_train.shape, Y_train.shape

X_train[0]

Y_test[0]

class_labels=["T-shirt/top","Trouser","Pullover","Dress","Coat","Sandal","Shirt","Sneaker","Bag","Ankle boot"]
'''
0 => T-shirt/top
1 => Trouser
2 => Pullover
3 => Dress
4 => Coat
5 => Sandal
6 => Shirt
7 => Sneaker
8 => Bag
9 => Ankle boot'''

"""**SHOW IMAGE**"""

plt.imshow(X_train[0], cmap='Greys')

plt.imshow(X_train[1], cmap = 'Greys')

plt.imshow(X_train[2],cmap='Greys')



"""***Show 100 Random Images in a single sheet*** **bold text**"""

plt.figure(figsize=(20,20))
j=1
for i in np.random.randint(0, 1000, 100):
  plt.subplot(10,10,j); j += 1
  plt.imshow(X_train[i], cmap='Greys')
  plt.axis('off')
  plt.title('{} / {}'.format(class_labels[Y_train[i]], Y_train[i]))

X_train.ndim

X_train=np.expand_dims(X_train, -1)
X_test=np.expand_dims(X_test, -1)

X_train.ndim
X_train.shape



"""*Feature Scaling*"""

X_train=X_train/255
X_test=X_test/255

X_train[0]

"""Split Dataset"""

from sklearn.model_selection import train_test_split
X_train,X_val,Y_train,Y_val=train_test_split(X_train, Y_train, test_size=0.2, random_state=2020)

X_train.shape,Y_train.shape

X_val.shape,Y_val.shape

"""***Convolutional Neural Network - Model Building.***"""

model=keras.models.Sequential([
                        keras.layers.Conv2D(filters=32, kernel_size=3, strides=(1,1),padding='valid',activation='relu',input_shape=[28,28,1]) ,
                        keras.layers.MaxPooling2D(pool_size=(2,2)),
                        keras.layers.Flatten(),
                        keras.layers.Dense(units=128,activation='relu'),
                        keras.layers.Dense(units=10,activation='softmax'),
])

model.summary()

model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])

model.fit(X_train, Y_train, epochs=20,batch_size=512,verbose=1,validation_data=(X_val,Y_val))

"""**Test The Model.**"""

model.predict(np.expand_dims(X_test[0],axis=0)).round(2)

np.argmax(model.predict(np.expand_dims(X_test[0],axis=0)).round(2))

Y_test[0]

Y_pred = model.predict(X_test).round(2)
Y_pred

model.evaluate(X_test,Y_test)

"""**Visualize output.**"""

plt.figure(figsize=(16,30))
j=1
for i in np.random.randint(0,1000,60):
  plt.subplot(10,6,j);j+=1
  plt.imshow(X_test[i].reshape(28,28),cmap='Greys')
  plt.title('Actual = {}/{} \nPredicted = {}/{}'.format(class_labels[Y_test[i]],Y_test[i],class_labels[np.argmax(Y_pred[i])],np.argmax(Y_pred[i])))
  plt.axis('off')

"""**Confusion Matrix.**"""

from sklearn.metrics import confusion_matrix
plt.figure(figsize=(16,9))
Y_pred_labels = [np.argmax(label) for label in Y_pred]
cm=confusion_matrix(Y_test,Y_pred_labels)
#show cm
sns.heatmap(cm,annot=True, fmt='d',xticklabels=class_labels, yticklabels=class_labels)

from sklearn.metrics import classification_report
cr = classification_report(Y_test, Y_pred_labels, target_names=class_labels)
print(cr)

"""**SAVE MODEL**"""

model.save('Fashion_classification_CNN_model.h5')

model_deploy=keras.models.load_model('Fashion_classification_CNN_model.h5')

model_deploy.predict(X_test).round(2)

model_deploy.predict(np.expand_dims(X_test[0],axis=0)).round(2)

np.argmax(model_deploy.predict(np.expand_dims(X_test[0],axis=0)))

"""**CONVOLUTIONAL NEAURAL NETWORK - Building Complex models**"""

cnn_model2=keras.models.Sequential([
                        keras.layers.Conv2D(filters=32, kernel_size=3, strides=(1,1),padding='valid',activation='relu',input_shape=[28,28,1]) ,
                        keras.layers.MaxPooling2D(pool_size=(2,2)),
                        keras.layers.Conv2D(filters=32, kernel_size=3, strides=(1,1),padding='same',activation='relu',input_shape=[]),
                        keras.layers.MaxPooling2D(pool_size=(2,2)),
                        keras.layers.Flatten(),
                        keras.layers.Dense(units=128,activation='relu'),
                        keras.layers.Dropout(0.25),
                        keras.layers.Dense(units=10,activation='softmax'),
                        keras.layers.Dropout(0.25),
                        keras.layers.Dense(units=128,activation='relu'),
                        keras.layers.Dense(units=10,activation='softmax'),
])

"""**NOW COMPILE THE MODEL**"""

cnn_model2.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=(['accuracy']))

"""**TRAIN THE MODEL**"""

from re import VERBOSE
cnn_model2.fit(X_train, Y_train, epochs=20, batch_size=512, verbose=1, validation_data=(X_val,Y_val))

cnn_model2.evaluate(X_test,Y_test)

"""**BUILDING VERY COMPLEX MODEL**"""

cnn_model3=keras.models.Sequential([
                        keras.layers.Conv2D(filters=32, kernel_size=3, strides=(1,1),padding='valid',activation='relu',input_shape=[28,28,1]) ,
                        keras.layers.MaxPooling2D(pool_size=(2,2)),
                        keras.layers.Conv2D(filters=32, kernel_size=3, strides=(2,2),padding='same',activation='relu',input_shape=[]),
                        keras.layers.MaxPooling2D(pool_size=(2,2)),
                        keras.layers.Conv2D(filters=32, kernel_size=3, strides=(2,2),padding='same',activation='relu',input_shape=[]),
                        keras.layers.MaxPooling2D(pool_size=(2,2)),
                        keras.layers.Flatten(),
                        keras.layers.Dense(units=128,activation='relu'),
                        keras.layers.Dropout(0.25),
                        keras.layers.Dense(units=256,activation='relu'),
                        keras.layers.Dropout(0.5),
                        keras.layers.Dense(units=256,activation='relu'),
                        keras.layers.Dropout(0.25),
                        keras.layers.Dense(units=128,activation='relu'),
                        keras.layers.Dropout(0.10),
                        keras.layers.Dense(units=10,activation='softmax')
])

#COMPILE THE MODEL
cnn_model3.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])

#TRAIN THE MODEL
cnn_model3.fit(X_train,Y_train,epochs=60,batch_size=512,verbose=1,validation_data=(X_val,Y_val))

cnn_model3.evaluate(X_test,Y_test)

"""**>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>FINISH PROJECT>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>**"""

